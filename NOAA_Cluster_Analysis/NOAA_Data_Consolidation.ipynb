{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2400d85",
   "metadata": {},
   "source": [
    "# Project: Improving Disaster Resilience\n",
    "\n",
    "## NOAA Historical Events Files - Data Preparation and Consolidation\n",
    "\n",
    "### \n",
    "### Disaster Resilience Project\n",
    "\n",
    "### Data Used: NOAA Storm Events Details from 1996 to 2022\n",
    "\n",
    "Andrew Sommers\n",
    "\n",
    "### Purpose\n",
    "\n",
    "Merge annual event files from NOAA into a countinuous dataset of NOAA Events.\n",
    "Convert the Property Damage column to a numeric value.\n",
    "Convert the Corp Damage column to a numeric value.\n",
    "Create a Unique Event for NOAA events as events that cross U.S. States will have different event numbers for each state:  \n",
    "    CUSTOM_EVENT_CODE provides a code for each unique NOAA event removing the duplication of the event across states. \n",
    "Output the combined NOAA event files. \n",
    "\n",
    "\n",
    "#### History üóìÔ∏è\n",
    "\n",
    "Date | Person | Details\n",
    "---- | ------ | -------\n",
    "04/12/2023| Andrew Sommers|   Create initial notebook\n",
    "06/01/2023| Andrew Sommers|   Adjust the working directory to use the NOAA folder under the Data folder\n",
    "08/21/2023| Andrew Sommers|   Update the documentation for the notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d07b82a",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "\n",
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8330ab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "#import requests # request http, api\n",
    "import pandas as pd # tabluar data\n",
    "#from functools import reduce\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = None # show all columns in display\n",
    "pd.options.display.max_rows = None # show all rows in display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4db75b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the notebooks data source directory to the Disaster Resilience  Directory - change this for your local environment\n",
    "# set the sourcing directory where the 'Data' folder is located; this is the raw data input files.  \n",
    "# this notebook assumes data files are located in a 'Data' folder in the following path:\n",
    "os.chdir('C:\\\\Users\\\\andre\\\\OneDrive\\\\Documents\\\\IndianaUniversity\\\\D592\\\\Project_Disaster_Resilience\\\\Data\\\\NOAA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd8d5c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function modifies the NOAA data to create values for DAMAGE_PROPERTY and DAMAGE_CROPS and pull a subset of columns\n",
    "def get_NOAA_data(year):\n",
    "    \n",
    "    # read the input csv from the Data directory given the path in the prior cell - all columns set to type string\n",
    "    NOAA_History_Adjusted = pd.read_csv(f'StormEvents_details-ftp_v1.0_d{year}.csv', dtype = str)\n",
    "    \n",
    "    #########################################################3\n",
    "    # convert the property damage and crop damage fields to a numeric value.\n",
    "    # The field is provided as a numeric value followed by a K, M, B, T as a multiplier of the value\n",
    "    # This section of converts the string to a numeric value \n",
    "    # the following mapping is used to turn the Property Damage - last character - into the representative value\n",
    "    value_replace_map = {\n",
    "        'K': 1000,\n",
    "        'M': 1000000,\n",
    "        'B': 1000000000,\n",
    "        'T': 1000000000000\n",
    "    }\n",
    "     \n",
    "    # \n",
    "    # this section has to remove Nan and 'K' values to 0 from DAMAGE PROPERTY column\n",
    "    # the  values (Example:  50.00K) must be converted to numeric values using the value_replace_table and lefthand characters of the column.\n",
    "    NOAA_History_Adjusted['DAMAGE_PROPERTY'] = NOAA_History_Adjusted['DAMAGE_PROPERTY'].fillna('0K') # replace  blanks with 0K\n",
    "    NOAA_History_Adjusted['DAMAGE_PROPERTY'] = NOAA_History_Adjusted['DAMAGE_PROPERTY'].replace(['0', 'K', 'M'],['0K', '0K', '0K']) # replace 0, K, and M with 0K\n",
    "    NOAA_History_Adjusted['factor'] = NOAA_History_Adjusted['DAMAGE_PROPERTY'].str[-1:] #get the last character from this column (will be K,M, B for thousands, millions, billions)\n",
    "    NOAA_History_Adjusted['DAMAGE_PROPERTY'] = NOAA_History_Adjusted['DAMAGE_PROPERTY'].str[:-1] #get all characters but the last character from the column - this is the actual numeric value\n",
    "    NOAA_History_Adjusted['DAMAGE_PROPERTY'] = NOAA_History_Adjusted['DAMAGE_PROPERTY'].astype(float) #change the string number value to a float value\n",
    "    NOAA_History_Adjusted[\"factor\"] = NOAA_History_Adjusted[\"factor\"].map(lambda x: value_replace_map[x]) #use the value replace map to replace K,M, B with values\n",
    "    NOAA_History_Adjusted[\"factor\"] = NOAA_History_Adjusted[\"factor\"].astype(float) #change the factor string number to a float value\n",
    "    NOAA_History_Adjusted['DAMAGE_PROPERTY'] = NOAA_History_Adjusted['DAMAGE_PROPERTY'] * NOAA_History_Adjusted['factor'] #calculate the full value of the property damage\n",
    "    NOAA_History_Adjusted = NOAA_History_Adjusted.drop(['factor'], axis = 1)   \n",
    "     # this section has to remove Nan and 'K' values to 0 from DAMAGE PROPERTY column\n",
    "    # the  values (Example:  50.00K) must be converted to numeric values using the value_replace_table and lefthand characters of the column.\n",
    "    NOAA_History_Adjusted['DAMAGE_CROPS'] = NOAA_History_Adjusted['DAMAGE_CROPS'].fillna('0K') # replace  blanks with 0K\n",
    "    NOAA_History_Adjusted['DAMAGE_CROPS'] = NOAA_History_Adjusted['DAMAGE_CROPS'].replace(['0', 'K', 'M'],['0K', '0K', '0K']) # replace 0, K, and M with 0K\n",
    "    NOAA_History_Adjusted['factor'] = NOAA_History_Adjusted['DAMAGE_CROPS'].str[-1:] #get the last character from this column (will be K,M, B for thousands, millions, billions)\n",
    "    NOAA_History_Adjusted['DAMAGE_CROPS'] = NOAA_History_Adjusted['DAMAGE_CROPS'].str[:-1] #get all characters but the last character from the column - this is the actual numeric value\n",
    "    NOAA_History_Adjusted['DAMAGE_CROPS'] = NOAA_History_Adjusted['DAMAGE_CROPS'].astype(float) #change the string number value to a float value\n",
    "    NOAA_History_Adjusted[\"factor\"] = NOAA_History_Adjusted[\"factor\"].map(lambda x: value_replace_map[x]) #use the value replace map to replace K,M, B with values\n",
    "    NOAA_History_Adjusted[\"factor\"] = NOAA_History_Adjusted[\"factor\"].astype(float) #change the factor string number to a float value\n",
    "    NOAA_History_Adjusted['DAMAGE_CROPS'] = NOAA_History_Adjusted['DAMAGE_CROPS'] * NOAA_History_Adjusted['factor'] #calculate the full value of the crop damage    \n",
    "        \n",
    "        \n",
    "    #extract the required columns, rename the columns to align to the FEMA dataset\n",
    "    NOAA_History_Analysis = NOAA_History_Adjusted[[\"YEAR\", \"EPISODE_ID\", \"EVENT_ID\", \"EVENT_TYPE\", \"EPISODE_NARRATIVE\", \"STATE\", \"STATE_FIPS\", \"CZ_NAME\", \"CZ_FIPS\", \"CZ_TYPE\", \"DAMAGE_PROPERTY\", \"DAMAGE_CROPS\"]].copy()\n",
    "    # Note:  The EPISODE_ID in the NOAA files does not provide a unique identifier of a NOAA event because\n",
    "    # the same event can impact multiple states, and the EPISODE_ID is different for each state.\n",
    "    # Using the Year, Month, Day, and Event Type in combination provides a good key to identify unique events that cross states\n",
    "    NOAA_History_Analysis[\"CUSTOM_EVENT_CODE\"] = NOAA_History_Adjusted[\"BEGIN_YEARMONTH\"]+NOAA_History_Adjusted[\"BEGIN_DAY\"]+NOAA_History_Adjusted[\"EPISODE_ID\"] # create a unique key for NOAA events\n",
    "\n",
    "     \n",
    "    return NOAA_History_Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1599b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for year :  1996\n",
      "Getting data for year :  1997\n",
      "Getting data for year :  1998\n",
      "Getting data for year :  1999\n",
      "Getting data for year :  2000\n",
      "Getting data for year :  2001\n",
      "Getting data for year :  2002\n",
      "Getting data for year :  2003\n",
      "Getting data for year :  2004\n",
      "Getting data for year :  2005\n",
      "Getting data for year :  2006\n",
      "Getting data for year :  2007\n",
      "Getting data for year :  2008\n",
      "Getting data for year :  2009\n",
      "Getting data for year :  2010\n",
      "Getting data for year :  2011\n",
      "Getting data for year :  2012\n",
      "Getting data for year :  2013\n",
      "Getting data for year :  2014\n",
      "Getting data for year :  2015\n",
      "Getting data for year :  2016\n",
      "Getting data for year :  2017\n",
      "Getting data for year :  2018\n",
      "Getting data for year :  2019\n",
      "Getting data for year :  2020\n",
      "Getting data for year :  2021\n",
      "Getting data for year :  2022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1561601"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a blank dataframe and concatenate each year of NOAA data into the dataframe\n",
    "df_NOAA = pd.DataFrame(columns = [\"YEAR\", \"EPISODE_ID\", \"EVENT_ID\", \"EVENT_TYPE\", \"EPISODE_NARRATIVE\", \"STATE\", \"STATE_FIPS\", \"CZ_NAME\", \"CZ_FIPS\", \"CZ_TYPE\", \"DAMAGE_PROPERTY\", \"DAMAGE_CROPS\", \"CUSTOM_EVENT_CODE\"])\n",
    "\n",
    "years = np.arange(1996,2023) \n",
    " \n",
    "for y in years:\n",
    "    print(\"Getting data for year : \", y)\n",
    "    df_NOAA = pd.concat([df_NOAA, get_NOAA_data(y)])\n",
    "    \n",
    "len(df_NOAA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c223020b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>EPISODE_NARRATIVE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>CZ_NAME</th>\n",
       "      <th>CZ_FIPS</th>\n",
       "      <th>CZ_TYPE</th>\n",
       "      <th>DAMAGE_PROPERTY</th>\n",
       "      <th>DAMAGE_CROPS</th>\n",
       "      <th>CUSTOM_EVENT_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996</td>\n",
       "      <td>2052149</td>\n",
       "      <td>5570068</td>\n",
       "      <td>High Wind</td>\n",
       "      <td>Strong gradient winds followed behind a line o...</td>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>17</td>\n",
       "      <td>HANCOCK</td>\n",
       "      <td>34</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199610292052149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1996</td>\n",
       "      <td>2052748</td>\n",
       "      <td>5570362</td>\n",
       "      <td>Flash Flood</td>\n",
       "      <td>Flash flood waters washed out a small bridge a...</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>40</td>\n",
       "      <td>BRYAN</td>\n",
       "      <td>13</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199610212052748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1996</td>\n",
       "      <td>2052749</td>\n",
       "      <td>5570363</td>\n",
       "      <td>Hail</td>\n",
       "      <td>Hail as large as softballs broke out car and t...</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>40</td>\n",
       "      <td>STEPHENS</td>\n",
       "      <td>137</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199610202052749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR EPISODE_ID EVENT_ID   EVENT_TYPE  \\\n",
       "0  1996    2052149  5570068    High Wind   \n",
       "1  1996    2052748  5570362  Flash Flood   \n",
       "2  1996    2052749  5570363         Hail   \n",
       "\n",
       "                                   EPISODE_NARRATIVE     STATE STATE_FIPS  \\\n",
       "0  Strong gradient winds followed behind a line o...  ILLINOIS         17   \n",
       "1  Flash flood waters washed out a small bridge a...  OKLAHOMA         40   \n",
       "2  Hail as large as softballs broke out car and t...  OKLAHOMA         40   \n",
       "\n",
       "    CZ_NAME CZ_FIPS CZ_TYPE  DAMAGE_PROPERTY  DAMAGE_CROPS CUSTOM_EVENT_CODE  \n",
       "0   HANCOCK      34       Z              0.0           0.0   199610292052149  \n",
       "1     BRYAN      13       C              0.0           0.0   199610212052748  \n",
       "2  STEPHENS     137       C              0.0           0.0   199610202052749  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NOAA.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53827e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end of file combine and save function 1\n"
     ]
    }
   ],
   "source": [
    "# output the combined data to a csv file\n",
    "os.chdir('C:\\\\Users\\\\andre\\\\OneDrive\\\\Documents\\\\IndianaUniversity\\\\D592\\\\Project_Disaster_Resilience\\\\Data\\\\NOAA')\n",
    "df_NOAA.to_csv(f'NOAA_EventHistory_1996_2022.csv', header=True, index=False)\n",
    "print('end of file combine and save function 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d161b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
